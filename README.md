# Conversion of Audioless Video to Speech Using AV-HuBERT Algorithm

## Overview
This project reconstructs speech from lip movements using deep learning techniques. The model processes uploaded video files, extracts visual features, and generates corresponding speech output.

## Features
- Uses deep learning for lip-reading and speech synthesis
- Converts lip movements to text and speech
- Streamlit-based web interface
- Supports MP4 video format for input

## Installation

### Prerequisites
Ensure you have the following installed:
- Python 3.8+
- pip
- Virtual environment (optional but recommended)

### Setup
```bash`
# Clone the repository
git clone https://github.com/yourusername/lip-reading-project.git
cd lip-reading-project

# Install dependencies
pip install -r requirements.txt
